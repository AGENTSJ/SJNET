{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[10,11]\n",
    "learningRate=0.0002\n",
    "thresh=1\n",
    "\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self,neuronCount=None,position=None,neuronvals=None):\n",
    "        \n",
    "        self.neuronCount = neuronCount\n",
    "        self.position = position\n",
    "        self.neuronvals = []\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.NodeDeltas=[] \n",
    "\n",
    "        #set by setintialweights and setnodedelta\n",
    "        self.previousLayer =None\n",
    "        self.AfterLayer =None\n",
    "\n",
    "        for i in range(self.neuronCount):\n",
    "\n",
    "            # self.bias.append(random.uniform(0.0001,1))\n",
    "            self.bias.append(1)\n",
    "\n",
    "        if position==1:\n",
    "            self.neuronvals = neuronvals\n",
    "    \n",
    "    def setInitialWeights(self,previousLayer):\n",
    "\n",
    "        self.previousLayer = previousLayer\n",
    "        test =[\n",
    "            [1,2,3,4]\n",
    "        ]\n",
    "        for i in range(self.neuronCount):\n",
    "            temp = []\n",
    "            for j in range(previousLayer.neuronCount):\n",
    "                temp.append(random.uniform(0.0001,1))\n",
    "                # temp.append(test[0][i+j])\n",
    "\n",
    "            self.weights.append(temp)\n",
    "\n",
    "    def setNodeDelta(self,AfterLayer):\n",
    "        \"\"\"\"\"\n",
    "        set nodedelta value for layers\n",
    "        \"\"\"\"\"\n",
    "        self.AfterLayer = AfterLayer\n",
    "        if self.position == -1:\n",
    "            # outputlayer\n",
    "            if len(self.NodeDeltas)==0:\n",
    "                for i in range(self.neuronCount):\n",
    "\n",
    "                    nodedelta = self.neuronvals[i]-dataset[i] #exepectd to change dimenston CHNGDIMN\n",
    "                    self.NodeDeltas.append(nodedelta)\n",
    "            else:\n",
    "                for i in range(self.neuronCount):\n",
    "\n",
    "                    nodedelta = self.neuronvals[i]-dataset[i] #exepectd to change dimenston CHNGDIMN\n",
    "                    self.NodeDeltas[i]=nodedelta\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if len(self.NodeDeltas)==0:\n",
    "\n",
    "                for i in range(self.neuronCount):\n",
    "                    nodedelta= 0\n",
    "                    for j in range(AfterLayer.neuronCount):\n",
    "                        nodedelta = nodedelta+AfterLayer.NodeDeltas[j]*self.weights[i][j]\n",
    "                    self.NodeDeltas.append(nodedelta)\n",
    "\n",
    "            else:\n",
    "                    for i in range(self.neuronCount):\n",
    "                        nodedelta= 0\n",
    "                        for j in range(AfterLayer.neuronCount):\n",
    "                            nodedelta = nodedelta+AfterLayer.NodeDeltas[j]*self.weights[i][j]\n",
    "                        self.NodeDeltas[i]=nodedelta\n",
    "\n",
    "    \n",
    "    def updateWeightsandBias(self):\n",
    "\n",
    "        len_weight = len(self.weights[0])# based on previous layer of no(neurons) lenof weights is set\n",
    "\n",
    "        for i in range(self.neuronCount):\n",
    "\n",
    "            for j in range(len_weight):\n",
    "                \n",
    "                new_Weight = self.weights[i][j] - learningRate * self.NodeDeltas[i] * self.previousLayer.neuronvals[j]\n",
    "                self.weights[i][j] = new_Weight\n",
    "            \n",
    "            new_Bias = self.bias[i] - learningRate * self.NodeDeltas[i]\n",
    "            self.bias[i]=new_Bias        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ann:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.LayerArr = []\n",
    "\n",
    "    def strap(self,layer1=None,layer2=None):\n",
    "        layer2.setInitialWeights(layer1)\n",
    "\n",
    "    def forward(self,layer1=None,layer2=None):  \n",
    "        if len(layer2.neuronvals)==0:\n",
    "            for i in range(layer2.neuronCount):\n",
    "                layer2.neuronvals.append(np.dot(layer1.neuronvals,layer2.weights[i])+layer2.bias[i])\n",
    "        else:\n",
    "            for i in range(layer2.neuronCount):\n",
    "                layer2.neuronvals[i]=np.dot(layer1.neuronvals,layer2.weights[i]+layer2.bias[i])\n",
    "            \n",
    "    def backPropagate(self,currentLayer=None,AfterLayer=None):\n",
    "\n",
    "        currentLayer.setNodeDelta(AfterLayer)\n",
    "        currentLayer.updateWeightsandBias()\n",
    "        \n",
    "    def compile(self):\n",
    "\n",
    "        for i in range(len(self.LayerArr)-1):\n",
    "\n",
    "            self.strap(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "    \n",
    "    def findError(self):\n",
    "        error = 0\n",
    "        for i in range(len(self.LayerArr[-1].neuronvals)):#CHNGDIMN\n",
    "            error = error+(dataset[i]-self.LayerArr[-1].neuronvals[i])**2\n",
    "        error = 0.5*error\n",
    "        return error\n",
    "    \n",
    "    def Train(self):\n",
    "\n",
    "        errorrate = 9999999 \n",
    "        layercount = len(self.LayerArr)\n",
    "\n",
    "        while (errorrate > thresh):\n",
    "\n",
    "            #forward propagation\n",
    "            for i in range(layercount-1):\n",
    "                self.forward(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "            \n",
    "            #error analysis\n",
    "            errorrate = self.findError()\n",
    "            # print(errorrate)\n",
    "            if(errorrate <thresh):\n",
    "                print(\"optimised\")\n",
    "                print(self.LayerArr[-1].neuronvals)\n",
    "                break\n",
    "          \n",
    "\n",
    "            #backward propagation\n",
    "            currentLayeridx = layercount-1  \n",
    "            for i in range(layercount-1):\n",
    "\n",
    "                if self.LayerArr[currentLayeridx].position ==-1:# handling output layer \n",
    "                    self.backPropagate(currentLayer=self.LayerArr[currentLayeridx])\n",
    "                    print(self.LayerArr[currentLayeridx].neuronvals)\n",
    "                    currentLayeridx=currentLayeridx-1\n",
    "                else:\n",
    "                    self.backPropagate(currentLayer=self.LayerArr[currentLayeridx],AfterLayer=self.LayerArr[currentLayeridx+1])\n",
    "                    currentLayeridx=currentLayeridx-1\n",
    "            \n",
    "                    \n",
    "    def bind(self,layer=None):\n",
    "        self.LayerArr.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.65702140055576, 4.085144185670522]\n",
      "[17.83979095568077, 21.208679791360726]\n",
      "[17.604666910050028, 20.909453472055517]\n",
      "[17.378802398003167, 20.621866747184658]\n",
      "[17.16169621631781, 20.345292337328516]\n",
      "[16.95288318466973, 20.079147998155985]\n",
      "[16.75193091366081, 19.822892481131774]\n",
      "[16.558436917846954, 19.576021925336086]\n",
      "[16.372026031322747, 19.338066627364825]\n",
      "[16.192348089305906, 19.10858814363265]\n",
      "[16.01907584414541, 18.887176685624475]\n",
      "[15.851903088405432, 18.673448773923425]\n",
      "[15.690542961277092, 18.467045121341616]\n",
      "[15.534726417643913, 18.26762871932025]\n",
      "[15.384200841759284, 18.074883105054823]\n",
      "[15.238728789754084, 17.888510789624856]\n",
      "[15.098086847138386, 17.708231829838667]\n",
      "[14.962064589140034, 17.533782528601442]\n",
      "[14.830463633175722, 17.364914250430232]\n",
      "[14.703096774009762, 17.201392340313333]\n",
      "[14.579787193250667, 17.042995135479487]\n",
      "[14.460367735789283, 16.88951306083428]\n",
      "[14.344680246614942, 16.740747799861204]\n",
      "[14.23257496217414, 16.596511533694965]\n",
      "[14.123909951074856, 16.4566262418723]\n",
      "[14.018550599499996, 16.32092305896609]\n",
      "[13.916369137186987, 16.189241681924976]\n",
      "[13.8172442002652, 16.061429823484087]\n",
      "[13.721060427627037, 15.937342707492403]\n",
      "[13.62770808784817, 15.816842602426764]\n",
      "[13.53708273397351, 15.699798389738735]\n",
      "[13.449084883752619, 15.586085164014506]\n",
      "[13.363619723145932, 15.475583862224783]\n",
      "[13.280596831134558, 15.368180919606033]\n",
      "[13.199929924055134, 15.263767949950104]\n",
      "[13.12153661784966, 15.162241448289834]\n",
      "[13.045338206770808, 15.063502514156454]\n",
      "[12.971259457218272, 14.967456593753292]\n",
      "[12.899228415502646, 14.874013239541528]\n",
      "[12.829176228442005, 14.783085885869514]\n",
      "[12.761036975794145, 14.6945916393994]\n",
      "[12.694747513615377, 14.608451083194645]\n",
      "[12.630247327716116, 14.524588093431309]\n",
      "[12.567478396455073, 14.44292966778534]\n",
      "[12.506385062178621, 14.363405764628986]\n",
      "[12.44691391067034, 14.285949152242683]\n",
      "[12.389013658028857, 14.21049526731492]\n",
      "[12.332635044440115, 14.136982082062728]\n",
      "[12.277730734353803, 14.065349979359981]\n",
      "[12.22425522261344, 13.99554163531023]\n",
      "[12.17216474612555, 13.927501908745837]\n",
      "[12.121417200686256, 13.861177737176309]\n",
      "[12.071972062613588, 13.79651803874608]\n",
      "[12.023790314861014, 13.733473619796095]\n",
      "[11.976834377312734, 13.67199708765482]\n",
      "[11.931068040984025, 13.612042768312676]\n",
      "[11.886456405870756, 13.55356662866006]\n",
      "[11.842965822211331, 13.4965262029929]\n",
      "[11.800563834941805, 13.440880523511643]\n",
      "[11.759219131140977, 13.386590054559601]\n",
      "[11.718901490276949, 13.333616630365011]\n",
      "[11.679581737080305, 13.281923396068068]\n",
      "[11.64123169688134, 13.231474751829854]\n",
      "[11.603824153260446, 13.18223629983427]\n",
      "[11.567332807871075, 13.134174794007404]\n",
      "[11.531732242304678, 13.087258092290826]\n",
      "[11.496997881875775, 13.04145511131664]\n",
      "[11.46310596121376, 12.996735783342341]\n",
      "[11.430033491555585, 12.95307101531322]\n",
      "[11.397758229640608, 12.9104326499288]\n",
      "[11.366258648115434, 12.868793428598106]\n",
      "[11.33551390736259, 12.828126956175925]\n",
      "[11.305503828672531, 12.788407667379541]\n",
      "[11.276208868683666, 12.749610794791575]\n",
      "[11.247610095019915, 12.711712338360945]\n",
      "[11.21968916305979, 12.674689036319291]\n",
      "[11.192428293775166, 12.63851833743556]\n",
      "[11.165810252581721, 12.603178374536233]\n",
      "[11.139818329146735, 12.568647939223176]\n",
      "[11.114436318103134, 12.534906457725299]\n",
      "[11.089648500621887, 12.501933967824023]\n",
      "[11.065439626797772, 12.469711096796365]\n",
      "[11.041794898806089, 12.438219040322558]\n",
      "[11.018699954790666, 12.407439542308563]\n",
      "[10.996140853445596, 12.377354875576586]\n",
      "[10.97410405925551, 12.347947823379496]\n",
      "[10.952576428361208, 12.319201661697665]\n",
      "[10.931545195019348, 12.291100142279099]\n",
      "[10.91099795862672, 12.263627476385999]\n",
      "[10.890922671281308, 12.236768319212917]\n",
      "[10.871307625853927, 12.210507754943803]\n",
      "[10.852141444545628, 12.184831282416853]\n",
      "[10.83341306790756, 12.159724801368029]\n",
      "optimised\n",
      "[10.815111744301127, 12.13517459922549]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# inputl = Layer(2,1,[2,3])\n",
    "inputl = Layer(neuronCount=2,position=1,neuronvals=[2,3])\n",
    "hidden = Layer(neuronCount=2,position=2,neuronvals=[])\n",
    "# hidden2 = Layer(neuronCount=2,position=3,neuronvals=[]) \n",
    "output = Layer(neuronCount=2,position=-1,neuronvals=[])\n",
    "\n",
    "Ann = Ann()\n",
    "Ann.bind(layer=inputl)\n",
    "Ann.bind(layer=hidden)\n",
    "# Ann.bind(layer=hidden2)\n",
    "Ann.bind(layer=output)\n",
    "Ann.compile()\n",
    "Ann.Train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
