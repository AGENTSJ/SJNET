{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating an Aritificial neural network of my own : SJNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Layer:\n",
    "       \n",
    "    def __init__(self,neuronCount=None,position=None,neuronvals=None,activation=\"linear\"):\n",
    "        \n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.activation = activation\n",
    "        self.neuronCount = neuronCount\n",
    "        self.position = position\n",
    "        self.neuronvals = []\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.NodeDeltas=[] \n",
    "        self.batchNeuronVals=[]\n",
    "        self.batchError =0\n",
    "        self.errorThresh=None\n",
    "        self.learningRate = None\n",
    "        self.gradArr=[]\n",
    "        \n",
    "        #set by setintialweights and setnodedelta\n",
    "        self.previousLayer =None\n",
    "        self.AfterLayer =None\n",
    "\n",
    "        for i in range(self.neuronCount):\n",
    "\n",
    "            self.bias.append(random.uniform(0.0001,1))\n",
    "            # self.bias.append(1)\n",
    "\n",
    "        if position==1:\n",
    "            self.neuronvals = neuronvals\n",
    "    \n",
    "    def activationfn(self):\n",
    "        funcs ={\n",
    "            \"linear\": lambda x :x,\n",
    "            \"relu\" : lambda x : max(0,x),\n",
    "            \"sigmoid\":lambda x : 1 / (1 + math.exp(-x))\n",
    "        }\n",
    "        return funcs[self.activation]\n",
    "\n",
    "    def setInitialWeights(self,previousLayer):\n",
    "        \"uses uniform distribution\"\n",
    "\n",
    "        self.previousLayer = previousLayer \n",
    "        fan_in = previousLayer.neuronCount\n",
    "        upperBound =1/fan_in\n",
    "        lowerBound = -upperBound\n",
    "        for i in range(self.neuronCount):\n",
    "            temp = []\n",
    "            for j in range(previousLayer.neuronCount):\n",
    "                \n",
    "                temp.append(random.uniform(lowerBound,upperBound))\n",
    "\n",
    "            self.weights.append(temp)\n",
    "\n",
    "        for i in range(self.neuronCount):\n",
    "\n",
    "            self.bias.append(random.uniform(lowerBound,upperBound))\n",
    "            \n",
    "    def loadLayer(self,weights,bias):\n",
    "        \"loads weights and biases into layer when using loadnetwork\"\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def setNodeDelta(self,AfterLayer,CurrentDataPoint=-1):\n",
    "        \"\"\"\"\"\n",
    "        set nodedelta value for layers\n",
    "        \"\"\"\"\"\n",
    "        self.AfterLayer = AfterLayer\n",
    "        if self.position == -1:\n",
    "            # outputlayer\n",
    "            if len(self.NodeDeltas)==0:\n",
    "                for i in range(self.neuronCount):\n",
    "\n",
    "                    nodedelta = self.neuronvals[i]-self.Y[CurrentDataPoint][i]\n",
    "                    if self.activation==\"sigmoid\":nodedelta*self.neuronvals[i]*(1-self.neuronvals[i]) #handling if sigmoid is used\n",
    "                    self.NodeDeltas.append(nodedelta)\n",
    "            else:\n",
    "                for i in range(self.neuronCount):\n",
    "\n",
    "                    nodedelta = self.neuronvals[i]-self.Y[CurrentDataPoint][i]\n",
    "                    if self.activation==\"sigmoid\":nodedelta*self.neuronvals[i]*(1-self.neuronvals[i]) #handling if sigmoid is used\n",
    "                    self.NodeDeltas[i]=nodedelta\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if len(self.NodeDeltas)==0:\n",
    "                \n",
    "                for i in range(self.neuronCount):\n",
    "                    nodedelta= 0\n",
    "                    for j in range(AfterLayer.neuronCount):\n",
    "                        \n",
    "                        nodedelta = nodedelta+AfterLayer.NodeDeltas[j]*AfterLayer.weights[j][i]\n",
    "                        if self.activation==\"sigmoid\":nodedelta*self.neuronvals[i]*(1-self.neuronvals[i]) #handling if sigmoid is used\n",
    "                        \n",
    "                    self.NodeDeltas.append(nodedelta)\n",
    "\n",
    "            else:\n",
    "                    for i in range(self.neuronCount):\n",
    "                        nodedelta= 0\n",
    "                        for j in range(AfterLayer.neuronCount):\n",
    "                            \n",
    "                            nodedelta = nodedelta+AfterLayer.NodeDeltas[j]*AfterLayer.weights[j][i]\n",
    "                            if self.activation==\"sigmoid\":nodedelta*self.neuronvals[i]*(1-self.neuronvals[i]) #handling if sigmoid is used\n",
    "                        self.NodeDeltas[i]=nodedelta\n",
    "    \n",
    "    def updateWeightsandBias(self):\n",
    "\n",
    "        len_weight = len(self.weights[0])# based on previous layer of no(neurons) lenof weights is set\n",
    "        \n",
    "        #setting gradient array\n",
    "        if len(self.gradArr)==0:\n",
    "\n",
    "            for i in range(self.neuronCount):\n",
    "                tempGrad=[]\n",
    "                for j in range(len_weight):\n",
    "                    \n",
    "                   tempGrad.append (   self.NodeDeltas[i] * self.previousLayer.neuronvals[j] )\n",
    "                \n",
    "                self.gradArr.append(np.array(tempGrad))\n",
    "        else:\n",
    "\n",
    "            for i in range(self.neuronCount):\n",
    "                tempGrad=[]\n",
    "                for j in range(len_weight):\n",
    "                    \n",
    "                    tempGrad.append(  self.NodeDeltas[i] * self.previousLayer.neuronvals[j] )\n",
    "                \n",
    "                self.gradArr[i]=np.array(tempGrad)\n",
    "\n",
    "        # performing l2 normalisation // handling exploding gradient \n",
    "        for i in range(self.neuronCount):\n",
    "\n",
    "            l2norm = np.linalg.norm(self.gradArr[i])\n",
    "            for j in range(len_weight):\n",
    "\n",
    "                # l2norm = np.linalg.norm(self.gradArr[i][j])\n",
    "                \n",
    "                if l2norm>1.0:\n",
    "                    self.gradArr[i][j]= self.gradArr[i][j]/l2norm\n",
    "                \n",
    "                new_Weight = self.weights[i][j] - self.learningRate *  self.gradArr[i][j] \n",
    "                self.weights[i][j] = new_Weight\n",
    "            \n",
    "            new_Bias = self.bias[i] - self.learningRate *  self.gradArr[i][j] \n",
    "            self.bias[i]=new_Bias\n",
    "   \n",
    "class Network:\n",
    "\n",
    "    def __init__(self,X=None,Y=None,errorThresh = 0.001,learningRate=0.02,epoch=200):\n",
    "        \"\"\"\"\n",
    "        NOTE : provide X and Y dataset with learning rate and errorthreshold \n",
    "        \"\"\"\"\"\n",
    "        self.LayerArr = []\n",
    "        self.X =X\n",
    "        self.Y = Y\n",
    "        self.errorThresh=errorThresh\n",
    "        self.learningRate = learningRate\n",
    "        self.epoch = epoch\n",
    "                  \n",
    "    def bind(self,layer1=None,layer2=None):\n",
    "        \"sets the initial weights of the ANN\"\n",
    "\n",
    "        layer2.setInitialWeights(layer1)\n",
    "\n",
    "    def forward(self,layer1=None,layer2=None): \n",
    "        \"performs forward passing for all layers in network with activation function\"\n",
    "\n",
    "        if len(layer2.neuronvals)==0:\n",
    "\n",
    "            for i in range(layer2.neuronCount):\n",
    "                activfn = layer2.activationfn()\n",
    "                layer2.neuronvals.append(activfn(np.dot(layer1.neuronvals,layer2.weights[i])+layer2.bias[i]))\n",
    "                \n",
    "            \n",
    "            if(layer2.position==-1):\n",
    "                temp =copy.deepcopy(layer2.neuronvals)\n",
    "                layer2.batchNeuronVals.append(temp)\n",
    "                \n",
    "\n",
    "        else:\n",
    "            for i in range(layer2.neuronCount):\n",
    "                activfn = layer2.activationfn()\n",
    "                layer2.neuronvals[i]=activfn(np.dot(layer1.neuronvals,layer2.weights[i])+layer2.bias[i])\n",
    "\n",
    "            if(layer2.position==-1):\n",
    "                temp =copy.deepcopy(layer2.neuronvals)\n",
    "                layer2.batchNeuronVals.append(temp)  \n",
    "                # layer2        \n",
    "            \n",
    "    def backPropagate(self,currentLayer=None,AfterLayer=None,CurrentDataPoint=-1):\n",
    "        \"\"\"\"\"\n",
    "        performs back propagation by\n",
    "\n",
    "        1. seting nodeDelta (a function in lasyer class)\n",
    "        2.Update werights and biases (a function in layer class)\n",
    "        \n",
    "        \"\"\"\"\"\n",
    "        #updating batch error after forwarding a datapoint completely(just at start of backprop)\n",
    "        if currentLayer.position ==-1:\n",
    "            error =0\n",
    "            for i in range(len(self.Y[CurrentDataPoint])):\n",
    "                error = error+(currentLayer.neuronvals[i]-self.Y[CurrentDataPoint][i])**2\n",
    "            currentLayer.batchError = currentLayer.batchError+error\n",
    "            \n",
    "        #normal backpropagation\n",
    "        currentLayer.setNodeDelta(AfterLayer,CurrentDataPoint=CurrentDataPoint)\n",
    "        currentLayer.updateWeightsandBias()\n",
    "         \n",
    "    def compile(self):\n",
    "        \"\"\"\"\"\n",
    "        calls bind function for every layer : initilizes weights in Ann\n",
    "        CALL THIS AFTER ADDING ALL LAYER WITH ANN.add()\n",
    "        \"\"\"\"\"\n",
    "        \n",
    "        for i in range(len(self.LayerArr)-1):\n",
    "\n",
    "            self.bind(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "\n",
    "    def BatchError(self):\n",
    "        \"\"\"\"\"\n",
    "        find the error after 1 epoch\n",
    "        \"\"\"\"\"\n",
    "        #batch error variable is updated in backpropagation function      \n",
    "        error = 1/len(self.Y)*self.LayerArr[-1].batchError\n",
    "        self.LayerArr[-1].batchError=0\n",
    "        return error\n",
    "      \n",
    "    def Train(self):\n",
    "        \"Trains the network for specified epoch\"\n",
    "        errorrate = 9999999\n",
    "        least_Error= 9999999\n",
    "        layercount = len(self.LayerArr)\n",
    "        eph =1\n",
    "        while (eph < self.epoch+1):\n",
    "            print(\"EPOCH.....\",eph)\n",
    "            #forward propagation\n",
    "            for N in range(len(self.X)):\n",
    "                \n",
    "                self.LayerArr[0].neuronvals = self.X[N]      \n",
    "\n",
    "                for i in range(layercount-1):\n",
    "                    self.forward(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "                \n",
    "                #backward propagation\n",
    "                currentLayeridx = layercount-1  \n",
    "                for i in range(layercount-1):\n",
    "                   \n",
    "                    if self.LayerArr[currentLayeridx].position ==-1:# handling output layer \n",
    "                        self.backPropagate(currentLayer=self.LayerArr[currentLayeridx],CurrentDataPoint=N)\n",
    "                        currentLayeridx=currentLayeridx-1\n",
    "                    else:\n",
    "                        self.backPropagate(currentLayer=self.LayerArr[currentLayeridx],AfterLayer=self.LayerArr[currentLayeridx+1])\n",
    "                        currentLayeridx=currentLayeridx-1\n",
    "                    \n",
    "\n",
    "            eph=eph+1       \n",
    "\n",
    "                \n",
    "            errorrate = self.BatchError()\n",
    "\n",
    "            if errorrate < least_Error:\n",
    "                self.save(name=\"BestError\")\n",
    "                least_Error = errorrate\n",
    "                \n",
    "            \n",
    "            print(\"error_rate\",errorrate)\n",
    "            \n",
    "            if(errorrate < self.errorThresh):\n",
    "                print(\"optimised\")\n",
    "                break\n",
    "            self.LayerArr[-1].batchNeuronVals = []\n",
    "    \n",
    "    def predict(self,inputvals):\n",
    "        \"returns predicted output by the network\"\n",
    "        self.LayerArr[0].neuronvals = inputvals\n",
    "        layercount = len(self.LayerArr)\n",
    "        for i in range(layercount-1):\n",
    "            self.forward(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "        return self.LayerArr[-1].neuronvals\n",
    "\n",
    "    def save(self,name=\"model\"):\n",
    "        net = {\n",
    "            \"layerCount\":len(self.LayerArr),\n",
    "            \"neuronDistribution\":[],\n",
    "            \"weights\":[],\n",
    "            \"biases\":[],\n",
    "            \"actvFns\":[],\n",
    "            \"nodeDeltas\":[]\n",
    "        }\n",
    "        for i in range(len(self.LayerArr)):\n",
    "\n",
    "            net[\"neuronDistribution\"].append(self.LayerArr[i].neuronCount)\n",
    "            net[\"actvFns\"].append(self.LayerArr[i].activation)\n",
    "            if i!=0:\n",
    "                net[\"weights\"].append(self.LayerArr[i].weights)\n",
    "                net[\"biases\"].append(self.LayerArr[i].bias)\n",
    "                net[\"nodeDeltas\"].append(self.LayerArr[i].NodeDeltas)\n",
    "        # print(\"saving.....\")\n",
    "        with open(f'{name}.json', 'w') as file:\n",
    "            json.dump(net, file)\n",
    "        # print(\"saved.....\")\n",
    "\n",
    "    def loadNetwork(self,network={}):  \n",
    "        \n",
    "        for i in range(network[\"layerCount\"]):\n",
    "            neuronCount = network[\"neuronDistribution\"][i]\n",
    "            position = i+1\n",
    "            activation= network[\"actvFns\"][i]\n",
    "            weights=[]\n",
    "            bias=[]\n",
    "\n",
    "            if i==network[\"layerCount\"]-2 : position = -1\n",
    "            layer = Layer(neuronCount=neuronCount,position=position,activation=activation)\n",
    "\n",
    "            if i!=0:\n",
    "                weights = network[\"weights\"][i-1]\n",
    "                bias = network[\"biases\"][i-1]\n",
    "                layer.loadLayer(weights=weights,bias=bias)\n",
    "\n",
    "            self.LayerArr.append(layer)\n",
    "\n",
    "    def add(self,layer=None):\n",
    "        \"\"\"\"\"\n",
    "        use this function to add layers into network in order such that\n",
    "        add input layer first and output layer last\n",
    "        \"\"\"\"\"\n",
    "        layer.X = self.X\n",
    "        layer.Y = self.Y\n",
    "        layer.errorThresh = self.errorThresh\n",
    "        layer.learningRate = self.learningRate\n",
    "        self.LayerArr.append(layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model with a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/abhijith/Desktop/Active/SJNET/Examples/data.csv\",header=None,delimiter=\",\")\n",
    "X=[]\n",
    "Y=[]\n",
    "for idx,row in enumerate(data.values):\n",
    "    x=[]\n",
    "    for i in range(2):\n",
    "        x.append(row[i])\n",
    "    X.append(x)\n",
    "    Y.append([row[2]])\n",
    "\n",
    "print(len(X))\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputLayer = Layer(neuronCount=2,position=1)\n",
    "hidden = Layer(neuronCount=10,position=2,activation=\"linear\")\n",
    "hidden2 = Layer(neuronCount=4,position=3,activation=\"linear\")\n",
    "output = Layer(neuronCount=1,position=-1,activation=\"linear\")\n",
    "\n",
    "network = Network(X=X,Y=Y,learningRate=0.0002,epoch=1000,errorThresh=0.1)\n",
    "\n",
    "network.add(layer=inputLayer)\n",
    "network.add(layer=hidden)\n",
    "network.add(layer=hidden2)\n",
    "network.add(layer=output)\n",
    "network.compile()\n",
    "network.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.predict(inputvals=[3.1, 2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.save(name=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = network.predict(inputvals=[3.1, 2.5])\n",
    "print(pred_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
