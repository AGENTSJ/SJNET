{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating an Aritificial neural network of my own : SJNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def __init__(self,X=None,Y=None,errorThresh = 0.01,learningRate=0.02,epoch=200):\n",
    "        \"\"\"\"\n",
    "        NOTE : provide X and Y dataset with learning rate and errorthreshold \n",
    "        \"\"\"\"\"\n",
    "        self.LayerArr = []\n",
    "        self.X =X\n",
    "        self.Y = Y\n",
    "        self.errorThresh=errorThresh\n",
    "        self.learningRate = learningRate\n",
    "        self.epoch = epoch\n",
    "             \n",
    "    def bind(self,layer1=None,layer2=None):\n",
    "        \"sets the initial weights of the ANN\"\n",
    "\n",
    "        layer2.setInitialWeights(layer1)\n",
    "\n",
    "    def forward(self,layer1=None,layer2=None): \n",
    "        \"performs forward passing for all layers in network with activation function\"\n",
    "\n",
    "        if len(layer2.neuronvals)==0:\n",
    "\n",
    "            for i in range(layer2.neuronCount):\n",
    "                activfn = layer2.activationfn()\n",
    "                layer2.neuronvals.append(activfn(np.dot(layer1.neuronvals,layer2.weights[i])+layer2.bias[i]))\n",
    "                \n",
    "            \n",
    "            if(layer2.position==-1):\n",
    "                temp =copy.deepcopy(layer2.neuronvals)\n",
    "                layer2.batchNeuronVals.append(temp)\n",
    "\n",
    "        else:\n",
    "            for i in range(layer2.neuronCount):\n",
    "                activfn = layer2.activationfn()\n",
    "                layer2.neuronvals[i]=activfn(np.dot(layer1.neuronvals,layer2.weights[i])+layer2.bias[i])\n",
    "\n",
    "            if(layer2.position==-1):\n",
    "                temp =copy.deepcopy(layer2.neuronvals)\n",
    "                layer2.batchNeuronVals.append(temp)\n",
    "            \n",
    "    def backPropagate(self,currentLayer=None,AfterLayer=None,CurrentDataPoint=-1):\n",
    "        \"\"\"\"\"\n",
    "        performs back propagation by\n",
    "\n",
    "        1. seting nodeDelta (a function in lasyer class)\n",
    "        2.Update werights and biases (a function in layer class)\n",
    "        \n",
    "        \"\"\"\"\"\n",
    "        currentLayer.setNodeDelta(AfterLayer,CurrentDataPoint=CurrentDataPoint)\n",
    "        currentLayer.updateWeightsandBias()\n",
    "        \n",
    "    def compile(self):\n",
    "        \"\"\"\"\"\n",
    "        calls bind function for every layer : initilizes weights in Ann\n",
    "        CALL THIS AFTER ADDING ALL LAYER WITH ANN.add()\n",
    "        \"\"\"\"\"\n",
    "        \n",
    "        for i in range(len(self.LayerArr)-1):\n",
    "\n",
    "            self.bind(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "\n",
    "    def BatchError(self):\n",
    "        \"\"\"\"\"\n",
    "        find the error after 1 epoch\n",
    "        \"\"\"\"\"\n",
    "        error = 0\n",
    "        \n",
    "        for i in range(len(self.LayerArr[-1].batchNeuronVals)):     \n",
    "            for j in range(len(self.Y[i])):\n",
    "                \n",
    "                error=error+0.5*(self.LayerArr[-1].batchNeuronVals[i][j]-self.Y[i][j])**2\n",
    "        return error\n",
    "      \n",
    "    def Train(self):\n",
    "        \"Trains the network for specified epoch\"\n",
    "        errorrate = 9999999 \n",
    "        layercount = len(self.LayerArr)\n",
    "        eph =1\n",
    "        while (eph < self.epoch+1):\n",
    "            print(\"EPOCH.....\",eph)\n",
    "            #forward propagation\n",
    "            for N in range(len(self.X)):\n",
    "                \n",
    "                self.LayerArr[0].neuronvals = self.X[N]      \n",
    "\n",
    "                for i in range(layercount-1):\n",
    "                    self.forward(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "                \n",
    "                #backward propagation\n",
    "                currentLayeridx = layercount-1  \n",
    "                for i in range(layercount-1):\n",
    "                   \n",
    "                    if self.LayerArr[currentLayeridx].position ==-1:# handling output layer \n",
    "                        self.backPropagate(currentLayer=self.LayerArr[currentLayeridx],CurrentDataPoint=N)\n",
    "                        currentLayeridx=currentLayeridx-1\n",
    "                    else:\n",
    "                        self.backPropagate(currentLayer=self.LayerArr[currentLayeridx],AfterLayer=self.LayerArr[currentLayeridx+1])\n",
    "                        currentLayeridx=currentLayeridx-1\n",
    "                    \n",
    "\n",
    "            eph=eph+1       \n",
    "                \n",
    "            errorrate = self.BatchError()\n",
    "            print(\"error_rate\",errorrate)\n",
    "            \n",
    "            if(errorrate < self.errorThresh):\n",
    "                print(\"optimised\")\n",
    "                print(self.LayerArr[-1].batchNeuronVals)\n",
    "                break\n",
    "            self.LayerArr[-1].batchNeuronVals = []\n",
    "    \n",
    "    def predict(self,inputvals):\n",
    "        self.LayerArr[0].neuronvals = inputvals\n",
    "        layercount = len(self.LayerArr)\n",
    "        for i in range(layercount-1):\n",
    "            self.forward(layer1=self.LayerArr[i],layer2=self.LayerArr[i+1])\n",
    "        print(self.LayerArr[-1].neuronvals)\n",
    "\n",
    "    def save(self,name=\"model\"):\n",
    "\n",
    "        with open(f\"{name}.txt\",\"w\") as f:\n",
    "            f.write(f\"name:{name}\\n Lcount:{len(self.LayerArr)}\")\n",
    "            f.write(\"\\nlayers\\n\")\n",
    "\n",
    "        for i in range(len(self.LayerArr)-1):\n",
    "            if i!=0:\n",
    "                with open(f\"{name}.txt\",\"a\") as f:\n",
    "                    \n",
    "                    f.write(f\"{self.LayerArr[i].neuronCount}\\n\")\n",
    "                    f.write(f\"{self.LayerArr[i].weights}\\n\")\n",
    "                    f.write(f\"{self.LayerArr[i].bias}\\n\")\n",
    "                \n",
    "    def add(self,layer=None):\n",
    "        \"\"\"\"\"\n",
    "        use this function to add layers into network in order such that\n",
    "        add input layer first and output layer last\n",
    "        \"\"\"\"\"\n",
    "        layer.X = self.X\n",
    "        layer.Y = self.Y\n",
    "        layer.errorThresh = self.errorThresh\n",
    "        layer.learningRate = self.learningRate\n",
    "        self.LayerArr.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "       \n",
    "    def __init__(self,neuronCount=None,position=None,neuronvals=None,activation=\"linear\"):\n",
    "        \n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.activation = activation\n",
    "        self.neuronCount = neuronCount\n",
    "        self.position = position\n",
    "        self.neuronvals = []\n",
    "        self.weights = []\n",
    "        self.bias = []\n",
    "        self.NodeDeltas=[] \n",
    "        self.batchNeuronVals=[]\n",
    "        self.errorThresh=None\n",
    "        self.learningRate = None\n",
    "        \n",
    "        #set by setintialweights and setnodedelta\n",
    "        self.previousLayer =None\n",
    "        self.AfterLayer =None\n",
    "\n",
    "        for i in range(self.neuronCount):\n",
    "\n",
    "            self.bias.append(random.uniform(0.0001,1))\n",
    "            # self.bias.append(1)\n",
    "\n",
    "        if position==1:\n",
    "            self.neuronvals = neuronvals\n",
    "    \n",
    "    def activationfn(self):\n",
    "        funcs ={\n",
    "            \"linear\": lambda x :x,\n",
    "            \"relu\" : lambda x : max(0,x),\n",
    "            \"sigmoid\":lambda x : 1 / (1 + math.exp(-x))\n",
    "        }\n",
    "        return funcs[self.activation]\n",
    "\n",
    "    def setInitialWeights(self,previousLayer):\n",
    "\n",
    "        self.previousLayer = previousLayer\n",
    "\n",
    "        for i in range(self.neuronCount):\n",
    "            temp = []\n",
    "            for j in range(previousLayer.neuronCount):\n",
    "                temp.append(random.uniform(0.0001,1))\n",
    "\n",
    "\n",
    "            self.weights.append(temp)\n",
    "  \n",
    "    def setNodeDelta(self,AfterLayer,CurrentDataPoint=-1):\n",
    "        \"\"\"\"\"\n",
    "        set nodedelta value for layers\n",
    "        \"\"\"\"\"\n",
    "        self.AfterLayer = AfterLayer\n",
    "        if self.position == -1:\n",
    "            # outputlayer\n",
    "            if len(self.NodeDeltas)==0:\n",
    "                for i in range(self.neuronCount):\n",
    "\n",
    "                    nodedelta = self.neuronvals[i]-self.Y[CurrentDataPoint][i] \n",
    "                    self.NodeDeltas.append(nodedelta)\n",
    "            else:\n",
    "                for i in range(self.neuronCount):\n",
    "\n",
    "                    nodedelta = self.neuronvals[i]-self.Y[CurrentDataPoint][i]\n",
    "                    self.NodeDeltas[i]=nodedelta\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if len(self.NodeDeltas)==0:\n",
    "                \n",
    "                for i in range(self.neuronCount):\n",
    "                    nodedelta= 0\n",
    "                    for j in range(AfterLayer.neuronCount):\n",
    "                        \n",
    "                        nodedelta = nodedelta+AfterLayer.NodeDeltas[j]*AfterLayer.weights[j][i]\n",
    "                        \n",
    "                    self.NodeDeltas.append(nodedelta)\n",
    "\n",
    "            else:\n",
    "                    for i in range(self.neuronCount):\n",
    "                        nodedelta= 0\n",
    "                        for j in range(AfterLayer.neuronCount):\n",
    "                            \n",
    "                            nodedelta = nodedelta+AfterLayer.NodeDeltas[j]*AfterLayer.weights[j][i]\n",
    "                        self.NodeDeltas[i]=nodedelta\n",
    "    \n",
    "    def updateWeightsandBias(self):\n",
    "\n",
    "        len_weight = len(self.weights[0])# based on previous layer of no(neurons) lenof weights is set\n",
    "        \n",
    "        \n",
    "        for i in range(self.neuronCount):\n",
    "\n",
    "            for j in range(len_weight):\n",
    "                \n",
    "                new_Weight = self.weights[i][j] - self.learningRate * self.NodeDeltas[i] * self.previousLayer.neuronvals[j]\n",
    "                self.weights[i][j] = new_Weight\n",
    "            \n",
    "            new_Bias = self.bias[i] - self.learningRate * self.NodeDeltas[i]\n",
    "            self.bias[i]=new_Bias  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model with a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\",header=None,delimiter=\",\")\n",
    "X=[]\n",
    "Y=[]\n",
    "for idx,row in enumerate(data.values):\n",
    "    x=[]\n",
    "    for i in range(2):\n",
    "        x.append(row[i])\n",
    "    X.append(x)\n",
    "    Y.append([row[2]])\n",
    "\n",
    "print(len(X))\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputl = Layer(neuronCount=2,position=1)\n",
    "hidden = Layer(neuronCount=10,position=2,activation=\"linear\")\n",
    "hidden2 = Layer(neuronCount=4,position=3,activation=\"linear\")\n",
    "output = Layer(neuronCount=1,position=-1,activation=\"linear\")\n",
    "\n",
    "network = Network(X=X,Y=Y,learningRate=0.0002,epoch=1000,errorThresh=3)\n",
    "\n",
    "network.add(layer=inputl)\n",
    "network.add(layer=hidden)\n",
    "network.add(layer=hidden2)\n",
    "network.add(layer=output)\n",
    "network.compile()\n",
    "network.Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.375892982612369]\n"
     ]
    }
   ],
   "source": [
    "network.predict(inputvals=[3.1, 2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.save(name=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
